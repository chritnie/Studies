import os
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

DATA_DIR = 'data'

def load_data():
    authors = []
    texts = []

    for author_dir in os.listdir(DATA_DIR):
        author_path = os.path.join(DATA_DIR, author_dir)
        if not os.path.isdir(author_path):
            continue

        for filename in os.listdir(author_path):
            if not filename.endswith('.txt'):
                continue

            file_path = os.path.join(author_path, filename)
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()

            authors.append(author_dir)
            texts.append(text)

    return pd.DataFrame({'author': authors, 'text': texts})

def train_model(df):
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(df['text'])
    y = df['author']

    clf = LogisticRegression()
    clf.fit(X, y)

    return clf, vectorizer

def predict_author(clf, vectorizer, text):
    X_new = vectorizer.transform([text])
    y_new = clf.predict(X_new)
    return y_new[0]

def evaluate_model(clf, vectorizer, X, y):
    y_pred = clf.predict(X)
    accuracy = accuracy_score(y, y_pred)
    precision = precision_score(y, y_pred, average='weighted')
    recall = recall_score(y, y_pred, average='weighted')
    f1 = f1_score(y, y_pred, average='weighted')

    print('Accuracy:', accuracy)
    print('Precision:', precision)
    print('Recall:', recall)
    print('F1 Score:', f1)

if __name__ == '__main__':
    df = load_data()
    clf, vectorizer = train_model(df)

    # Добавление новых авторов и текстов
    new_authors = ['Franz Kafka', 'Charles Dickens', 'Agatha Chritstie', 'Lovecraft', 'Walter Scott', 'William Shakespeare']
    new_texts = ['the time carelessly, as they did in the golden world. OLIVER. What, you', 'brook such disgrace well as he shall run into, in that it is thing of his own']
    for i in range(len(new_authors)):
        author_dir = os.path.join(DATA_DIR, new_authors[i])
        os.makedirs(author_dir, exist_ok=True)

        filename = f'{new_authors[i]}_{len(os.listdir(author_dir))+1}.txt'
        file_path = os.path.join(author_dir, filename)

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_texts[i])

    # Оценка качества модели
    X = vectorizer.transform(df['text'])
    y = df['author']
    evaluate_model(clf, vectorizer, X, y)

    # Предсказание авторства для новых текстов
    for author_dir in os.listdir(DATA_DIR):
        author_path = os.path.join(DATA_DIR, author_dir)
        if not os.path.isdir(author_path):
            continue

        for filename in os.listdir(author_path):
            if not filename.endswith('.txt'):
                continue
