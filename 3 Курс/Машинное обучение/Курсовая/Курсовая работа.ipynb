{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Модель 1**"
      ],
      "metadata": {
        "id": "zEG417l9EOBX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agbVcJC68zV3",
        "outputId": "9a8ae1cc-c1b2-4d56-bbc1-2d424f2540b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75\n",
            "Precision: 0.5833333333333333\n",
            "Recall: 0.75\n",
            "F1 Score: 0.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "DATA_DIR = 'data'\n",
        "\n",
        "def load_data():\n",
        "    authors = []\n",
        "    texts = []\n",
        "\n",
        "    for author_dir in os.listdir(DATA_DIR):\n",
        "        author_path = os.path.join(DATA_DIR, author_dir)\n",
        "        if not os.path.isdir(author_path):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(author_path):\n",
        "            if not filename.endswith('.txt'):\n",
        "                continue\n",
        "\n",
        "            file_path = os.path.join(author_path, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "\n",
        "            authors.append(author_dir)\n",
        "            texts.append(text)\n",
        "\n",
        "    return pd.DataFrame({'author': authors, 'text': texts})\n",
        "\n",
        "def train_model(df):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(df['text'])\n",
        "    y = df['author']\n",
        "\n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    return clf, vectorizer\n",
        "\n",
        "def predict_author(clf, vectorizer, text):\n",
        "    X_new = vectorizer.transform([text])\n",
        "    y_new = clf.predict(X_new)\n",
        "    return y_new[0]\n",
        "\n",
        "def evaluate_model(clf, vectorizer, X, y):\n",
        "    y_pred = clf.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision = precision_score(y, y_pred, average='weighted')\n",
        "    recall = recall_score(y, y_pred, average='weighted')\n",
        "    f1 = f1_score(y, y_pred, average='weighted')\n",
        "\n",
        "    print('Accuracy:', accuracy)\n",
        "    print('Precision:', precision)\n",
        "    print('Recall:', recall)\n",
        "    print('F1 Score:', f1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    df = load_data()\n",
        "    clf, vectorizer = train_model(df)\n",
        "\n",
        "    new_authors = ['Franz Kafka', 'Charles Dickens', 'Agatha Chritstie', 'Lovecraft', 'Walter Scott', 'William Shakespeare']\n",
        "    new_texts = ['the time carelessly, as they did in the golden world. OLIVER. What, you', 'brook such disgrace well as he shall run into, in that it is thing of his own']\n",
        "    for i in range(len(new_authors)):\n",
        "        author_dir = os.path.join(DATA_DIR, new_authors[i])\n",
        "        os.makedirs(author_dir, exist_ok=True)\n",
        "\n",
        "        filename = f'{new_authors[i]}_{len(os.listdir(author_dir))+1}.txt'\n",
        "        file_path = os.path.join(author_dir, filename)\n",
        "\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(new_texts[i])\n",
        "\n",
        "    X = vectorizer.transform(df['text'])\n",
        "    y = df['author']\n",
        "    evaluate_model(clf, vectorizer, X, y)\n",
        "\n",
        "    for author_dir in os.listdir(DATA_DIR):\n",
        "        author_path = os.path.join(DATA_DIR, author_dir)\n",
        "        if not os.path.isdir(author_path):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(author_path):\n",
        "            if not filename.endswith('.txt'):\n",
        "                continue"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Модель 2**"
      ],
      "metadata": {
        "id": "w242-NJsElLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Embedding, Conv1D, MaxPooling1D, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import GRU\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "with open('corpus.txt', 'r', encoding='utf-8') as f:\n",
        "    corpus = f.read().splitlines()\n",
        "\n",
        "authors = ['Charles Dickens', 'Jane Austen', 'William Shakespeare', 'Lovecraft', 'Walter Scott', 'Agatha Christie', 'Franz Kafka']\n",
        "\n",
        "author_ids = []\n",
        "for text in corpus:\n",
        "    if not text.strip():\n",
        "        continue\n",
        "    author_name_match = re.match(r\"\\s*\\((\\w+\\s*\\w+)\\)\", text)\n",
        "    if author_name_match:\n",
        "        author_name = author_name_match.group(1)\n",
        "        try:\n",
        "            author_ids.append(authors.index(author_name))\n",
        "        except ValueError:\n",
        "            print(f\"Skipping text: {text.strip()}\")\n",
        "    else:\n",
        "        print(f\"Skipping text: {text.strip()}\")\n",
        "\n",
        "texts = []\n",
        "for text in corpus:\n",
        "    parts = text.split(') ')\n",
        "    if len(parts) < 2:\n",
        "        continue\n",
        "    text_without_author = parts[1].lower()\n",
        "    texts.append(text_without_author)\n",
        "\n",
        "print(author_ids, texts)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "maxlen = 1000\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "author_ids_one_hot = tf.keras.utils.to_categorical(author_ids)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, author_ids_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128, input_length=maxlen))\n",
        "\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "\n",
        "model.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
        "\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(len(authors), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=32)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "new_texts = [\"I know not why my dreams were so wild that night; but ere the waning and fantastically gibbous moon had risen far above the eastern plain, I was awake in a cold perspiration, determined to sleep no more.\",\n",
        "             \"ORLANDO. I will not, till I please; you shall hear me. My father charg'd you in his will to give me good education: you have train'd me like a peasant, obscuring and hiding from me all gentleman-like qualities.\",\n",
        "             \"They alighted at the street corner, and dismissing their conveyance, walked to the house. To their first knock at the door there was no response. A second met with the like result. But in answer to the third, which was of a more vigorous kind, the parlour window-sash was gently raised, and a musical voice cried:\",\n",
        "             \"In the meanwhile Mr. Ireby found some amusement in detaining the northern drover at his ancient hall. He caused a cold round of beef to be placed before the Scot in the butler's pantry, together with a foaming tankard of home-brewed, and took pleasure in seeing the hearty appetite with which these unwonted edibles were discussed by Robin Oig M'Combich.\"\n",
        "             \"An thony re joined his flock of sheep. Miss Tay lor, the youngest and most skit tish of the party, in stantly at tacked him. 'Oh, Mr Cade, was that an old friend of yours?'\",\n",
        "             \"'You will probably think me very foolish, Monsieur Poirot, but Lord Cranshaw was telling me last night how wonderfully you cleared up the mystery of his nephew's death, and I felt that I just must have your advice. I dare say it's only a silly hoax - Gregory says so - but it's just worrying me to death.'\",\n",
        "             \"This noble body, equipped with everything necessary, almost to the point of bursting, also appeared to carry freedom around with it. That seem to be located somewhere or other in its teeth, and its joy in living came with such strong passion from its throat that it was not easy for spectators to keep watching.\",\n",
        "             \"He did not quite reject the idea that he should see a doctor the next time he had the chance, but whatever he did - and this was something on which he could advise himself - he wanted to spend all Sunday mornings in future better than he had spent this one.\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
        "new_padded_sequences = pad_sequences(new_sequences, maxlen=maxlen)\n",
        "\n",
        "predictions = model.predict(new_padded_sequences)\n",
        "\n",
        "for i, text in enumerate(new_texts):\n",
        "    print(text, 'is written by', authors[np.argmax(predictions[i])])\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 2])\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "print(classification_report(y_true, y_pred, labels=range(len(authors)), target_names=authors))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "lOqyUH54EoK1",
        "outputId": "c580dc7f-d3a9-4f85-8202-779983d23678"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-94a071bad478>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpus.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'corpus.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Модель 3**"
      ],
      "metadata": {
        "id": "0Rf5jBqyFlfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import re\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Embedding, Conv1D, MaxPooling1D, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import GRU\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "with open('corpus.txt', 'r', encoding='utf-8') as f:\n",
        "    corpus = f.read().splitlines()\n",
        "\n",
        "authors = ['Charles Dickens', 'Jane Austen', 'William Shakespeare', 'Lovecraft', 'Walter Scott', 'Agatha Christie', 'Franz Kafka']\n",
        "\n",
        "author_ids = []\n",
        "for text in corpus:\n",
        "    if not text.strip():\n",
        "        continue\n",
        "    author_name_match = re.match(r\"\\s*\\((\\w+\\s*\\w+)\\)\", text)\n",
        "    if author_name_match:\n",
        "        author_name = author_name_match.group(1)\n",
        "        try:\n",
        "            author_ids.append(authors.index(author_name))\n",
        "        except ValueError:\n",
        "            print(f\"Skipping text: {text.strip()}\")\n",
        "    else:\n",
        "        print(f\"Skipping text: {text.strip()}\")\n",
        "\n",
        "texts = []\n",
        "for text in corpus:\n",
        "    parts = text.split(') ')\n",
        "    if len(parts) < 2:\n",
        "        continue\n",
        "    text_without_author = parts[1].lower()\n",
        "    texts.append(text_without_author)\n",
        "\n",
        "labels = np.array(author_ids)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "max_len = max([len(x) for x in sequences])\n",
        "\n",
        "x = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "indices = np.arange(x.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "labels = labels[indices]\n",
        "num_validation_samples = int(0.2 * x.shape[0])\n",
        "x_train = x[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = x[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 128, input_length=max_len))\n",
        "model.add(Conv1D(32, 7, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(authors), activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, batch_size=128)\n",
        "\n",
        "new_texts = [\"I know not why my dreams were so wild that night; but ere the waning and fantastically gibbous moon had risen far above the eastern plain, I was awake in a cold perspiration, determined to sleep no more.\",\n",
        "             \"ORLANDO. I will not, till I please; you shall hear me. My father charg'd you in his will to give me good education: you have train'd me like a peasant, obscuring and hiding from me all gentleman-like qualities.\",\n",
        "             \"They alighted at the street corner, and dismissing their conveyance, walked to the house. To their first knock at the door there was no response. A second met with the like result. But in answer to the third, which was of a more vigorous kind, the parlour window-sash was gently raised, and a musical voice cried:\",\n",
        "             \"In the meanwhile Mr. Ireby found some amusement in detaining the northern drover at his ancient hall. He caused a cold round of beef to be placed before the Scot in the butler's pantry, together with a foaming tankard of home-brewed, and took pleasure in seeing the hearty appetite with which these unwonted edibles were discussed by Robin Oig M'Combich.\"\n",
        "             \"An thony re joined his flock of sheep. Miss Tay lor, the youngest and most skit tish of the party, in stantly at tacked him. 'Oh, Mr Cade, was that an old friend of yours?'\",\n",
        "             \"'You will probably think me very foolish, Monsieur Poirot, but Lord Cranshaw was telling me last night how wonderfully you cleared up the mystery of his nephew's death, and I felt that I just must have your advice. I dare say it's only a silly hoax - Gregory says so - but it's just worrying me to death.'\",\n",
        "             \"This noble body, equipped with everything necessary, almost to the point of bursting, also appeared to carry freedom around with it. That seem to be located somewhere or other in its teeth, and its joy in living came with such strong passion from its throat that it was not easy for spectators to keep watching.\",\n",
        "             \"He did not quite reject the idea that he should see a doctor the next time he had the chance, but whatever he did - and this was something on which he could advise himself - he wanted to spend all Sunday mornings in future better than he had spent this one.\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
        "new_padded_sequences = pad_sequences(new_sequences, maxlen=max_len)\n",
        "\n",
        "predictions = model.predict(new_padded_sequences)\n",
        "\n",
        "for i, text in enumerate(new_texts):\n",
        "    print(text, 'is written by', authors[np.argmax(predictions[i])])\n",
        "\n",
        "plt.plot(history.history['acc'], label='acc')\n",
        "plt.plot(history.history['val_acc'], label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 2])\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p4ks58_YFna1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
